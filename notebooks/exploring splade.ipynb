{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pa6BCOi6t47k","executionInfo":{"status":"ok","timestamp":1686264235235,"user_tz":180,"elapsed":59036,"user":{"displayName":"Leonardo Bernardi de Avila","userId":"02397315053255109793"}},"outputId":"7984895f-2af0-4f83-a014-90d94b555ed9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting beir\n","  Downloading beir-1.0.1.tar.gz (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting sentence-transformers (from beir)\n","  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pytrec_eval (from beir)\n","  Downloading pytrec_eval-0.5.tar.gz (15 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting faiss_cpu (from beir)\n","  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting elasticsearch==7.9.1 (from beir)\n","  Downloading elasticsearch-7.9.1-py2.py3-none-any.whl (219 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.2/219.2 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets (from beir)\n","  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from elasticsearch==7.9.1->beir) (1.26.15)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from elasticsearch==7.9.1->beir) (2022.12.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (1.22.4)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (9.0.0)\n","Collecting dill<0.3.7,>=0.3.0 (from datasets->beir)\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (2.27.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (4.65.0)\n","Collecting xxhash (from datasets->beir)\n","  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets->beir)\n","  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (2023.4.0)\n","Collecting aiohttp (from datasets->beir)\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.11.0 (from datasets->beir)\n","  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (23.1)\n","Collecting responses<0.19 (from datasets->beir)\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (6.0)\n","Collecting transformers<5.0.0,>=4.6.0 (from sentence-transformers->beir)\n","  Downloading transformers-4.30.0-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m126.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (0.15.2+cu118)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (1.10.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (3.8.1)\n","Collecting sentencepiece (from sentence-transformers->beir)\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (2.0.12)\n","Collecting multidict<7.0,>=4.5 (from aiohttp->datasets->beir)\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets->beir)\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0 (from aiohttp->datasets->beir)\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets->beir)\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets->beir)\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets->beir) (3.12.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets->beir) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->beir) (3.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers->beir) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers->beir) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers->beir) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers->beir) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers->beir) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers->beir) (16.0.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->beir) (2022.10.31)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers->beir)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m138.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers->beir)\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers->beir) (8.1.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers->beir) (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->beir) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->beir) (2022.7.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers->beir) (3.1.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers->beir) (8.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->beir) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers->beir) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers->beir) (1.3.0)\n","Building wheels for collected packages: beir, pytrec_eval, sentence-transformers\n","  Building wheel for beir (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for beir: filename=beir-1.0.1-py3-none-any.whl size=62502 sha256=f2d98dc3e6286d5511584365338374cf94a97a2c28b9aa5766097e88e5de278d\n","  Stored in directory: /root/.cache/pip/wheels/db/39/65/c3e53a900805045248fd6bed1b8ce0cc271bac7b3c9dd0f138\n","  Building wheel for pytrec_eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pytrec_eval: filename=pytrec_eval-0.5-cp310-cp310-linux_x86_64.whl size=293478 sha256=841f93f102b03384c7d9eeb090ac0be588dd0653d357b07e99793f8a0796c003\n","  Stored in directory: /root/.cache/pip/wheels/51/3a/cd/dcc1ddfc763987d5cb237165d8ac249aa98a23ab90f67317a8\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=01a88f7eda86795377c1941873a26134b09a2f2266446e2fe9756b1333b5c4dd\n","  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n","Successfully built beir pytrec_eval sentence-transformers\n","Installing collected packages: tokenizers, sentencepiece, safetensors, faiss_cpu, xxhash, pytrec_eval, multidict, frozenlist, elasticsearch, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, transformers, aiohttp, datasets, sentence-transformers, beir\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 beir-1.0.1 datasets-2.12.0 dill-0.3.6 elasticsearch-7.9.1 faiss_cpu-1.7.4 frozenlist-1.3.3 huggingface-hub-0.15.1 multidict-6.0.4 multiprocess-0.70.14 pytrec_eval-0.5 responses-0.18.0 safetensors-0.3.1 sentence-transformers-2.2.2 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.30.0 xxhash-3.2.0 yarl-1.9.2\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for SPLADE (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting hydra-core\n","  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting omegaconf<2.4,>=2.2 (from hydra-core)\n","  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting antlr4-python3-runtime==4.9.* (from hydra-core)\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core) (23.1)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.4,>=2.2->hydra-core) (6.0)\n","Building wheels for collected packages: antlr4-python3-runtime\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=daf437fc1c8ea15a48c7bf8a82dba1e3fa3b5f6c5715599dc9c587d45d93e890\n","  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n","Successfully built antlr4-python3-runtime\n","Installing collected packages: antlr4-python3-runtime, omegaconf, hydra-core\n","  Attempting uninstall: antlr4-python3-runtime\n","    Found existing installation: antlr4-python3-runtime 4.8\n","    Uninstalling antlr4-python3-runtime-4.8:\n","      Successfully uninstalled antlr4-python3-runtime-4.8\n","  Attempting uninstall: omegaconf\n","    Found existing installation: omegaconf 2.1.2\n","    Uninstalling omegaconf-2.1.2:\n","      Successfully uninstalled omegaconf-2.1.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","splade 2.1 requires omegaconf==2.1.2, but you have omegaconf 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed antlr4-python3-runtime-4.9.3 hydra-core-1.3.2 omegaconf-2.3.0\n"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":1}],"source":["%%shell\n","pip install beir\n","pip install git+https://github.com/naver/splade.git -q\n","pip install hydra-core --upgrade"]},{"cell_type":"code","source":["!SPLADE_CONFIG_NAME=config_splade python -m src.all"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"olr2dJI89NnJ","executionInfo":{"status":"ok","timestamp":1686264235236,"user_tz":180,"elapsed":10,"user":{"displayName":"Leonardo Bernardi de Avila","userId":"02397315053255109793"}},"outputId":"6038babb-f69e-4e21-f79b-a6f84511299e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/bin/python3: Error while finding module specification for 'src.all' (ModuleNotFoundError: No module named 'src')\n"]}]},{"cell_type":"code","source":["!wget https://download.europe.naverlabs.com/splade/sigir22/data.tar.gz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Llxw7bM9U6k","executionInfo":{"status":"ok","timestamp":1686264400423,"user_tz":180,"elapsed":165191,"user":{"displayName":"Leonardo Bernardi de Avila","userId":"02397315053255109793"}},"outputId":"3f057f85-d5e2-4750-b8ac-4c5d182d89d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-06-08 22:43:49--  https://download.europe.naverlabs.com/splade/sigir22/data.tar.gz\n","Resolving download.europe.naverlabs.com (download.europe.naverlabs.com)... 110.234.56.25\n","Connecting to download.europe.naverlabs.com (download.europe.naverlabs.com)|110.234.56.25|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2445966455 (2.3G) [application/x-gzip]\n","Saving to: ‘data.tar.gz’\n","\n","data.tar.gz         100%[===================>]   2.28G  14.9MB/s    in 2m 44s  \n","\n","2023-06-08 22:46:34 (14.2 MB/s) - ‘data.tar.gz’ saved [2445966455/2445966455]\n","\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/naver/splade.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ICmCDa8v9vXk","executionInfo":{"status":"ok","timestamp":1686264401044,"user_tz":180,"elapsed":631,"user":{"displayName":"Leonardo Bernardi de Avila","userId":"02397315053255109793"}},"outputId":"78ca052b-6645-4b87-e1af-60cce5ec34f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'splade'...\n","remote: Enumerating objects: 667, done.\u001b[K\n","remote: Counting objects: 100% (200/200), done.\u001b[K\n","remote: Compressing objects: 100% (119/119), done.\u001b[K\n","remote: Total 667 (delta 109), reused 117 (delta 71), pack-reused 467\u001b[K\n","Receiving objects: 100% (667/667), 3.13 MiB | 38.67 MiB/s, done.\n","Resolving deltas: 100% (351/351), done.\n"]}]},{"cell_type":"code","source":["%%shell\n","cd /content/splade/\n","export PYTHONPATH=$PYTHONPATH:$(pwd)\n","export SPLADE_CONFIG_NAME=\"config_default.yaml\"\n","python3 -m splade.all \\\n","  config.checkpoint_dir=experiments/debug/checkpoint \\\n","  config.index_dir=experiments/debug/index \\\n","  config.out_dir=experiments/debug/out"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AOecqTO2FWCF","executionInfo":{"status":"ok","timestamp":1686264511476,"user_tz":180,"elapsed":110434,"user":{"displayName":"Leonardo Bernardi de Avila","userId":"02397315053255109793"}},"outputId":"66683485-4f59-4c3f-cbef-bf34df910f53"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/splade/splade/flops.py:31: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=CONFIG_PATH, config_name=CONFIG_NAME)\n","/content/splade/splade/index.py:12: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=CONFIG_PATH, config_name=CONFIG_NAME)\n","/content/splade/splade/evaluate.py:12: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=CONFIG_PATH, config_name=CONFIG_NAME)\n","/content/splade/splade/retrieve.py:13: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=CONFIG_PATH, config_name=CONFIG_NAME)\n","2023-06-08 22:46:40.053037: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-06-08 22:46:40.110317: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-06-08 22:46:41.119666: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/content/splade/splade/train.py:20: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=CONFIG_PATH, config_name=CONFIG_NAME)\n","/content/splade/splade/utils/index_figure.py:12: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=CONFIG_PATH, config_name=CONFIG_NAME)\n","/content/splade/splade/all.py:13: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=CONFIG_PATH, config_name=CONFIG_NAME)\n","/usr/local/lib/python3.10/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config_default': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n","  warnings.warn(msg, UserWarning)\n","/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n","See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n","  ret = run_job(\n","config:\n","  lr: 2.0e-05\n","  seed: 123\n","  gradient_accumulation_steps: 1\n","  weight_decay: 0.01\n","  validation_metrics:\n","  - MRR@10\n","  - recall@100\n","  - recall@200\n","  - recall@500\n","  pretrained_no_yamlconfig: false\n","  nb_iterations: 10\n","  train_batch_size: 6\n","  eval_batch_size: 8\n","  index_retrieve_batch_size: 6\n","  record_frequency: 3\n","  train_monitoring_freq: 2\n","  warmup_steps: 5\n","  max_length: 10\n","  fp16: false\n","  augment_pairs: in_batch_negatives\n","  matching_type: splade\n","  monitoring_ckpt: loss\n","  loss: InBatchPairwiseNLL\n","  regularizer:\n","    FLOPS:\n","      lambda_q: 0.0005\n","      lambda_d: 0.0003\n","      T: 3\n","      targeted_rep: rep\n","      reg: FLOPS\n","  tokenizer_type: distilbert-base-uncased\n","  top_k: 5\n","  threshold: 0.4\n","  eval_metric:\n","  - - mrr_10\n","    - recall\n","  checkpoint_dir: experiments/debug/checkpoint\n","  index_dir: experiments/debug/index\n","  out_dir: experiments/debug/out\n","data:\n","  type: triplets\n","  TRAIN_DATA_DIR: data/toy_data/triplets\n","  VALIDATION_SIZE_FOR_LOSS: 20\n","  VALIDATION_FULL_RANKING:\n","    D_COLLECTION_PATH: data/toy_data/val_collection\n","    Q_COLLECTION_PATH: data/toy_data/val_queries\n","    QREL_PATH: data/toy_data/qrel/qrel.json\n","    TOP_K: 20\n","  COLLECTION_PATH: data/toy_data/full_collection\n","  Q_COLLECTION_PATH:\n","  - data/toy_data/dev_queries\n","  EVAL_QREL_PATH:\n","  - data/toy_data/qrel/qrel.json\n","  flops_queries: data/toy_data/dev_queries\n","init_dict:\n","  model_type_or_dir: distilbert-base-uncased\n","  model_type_or_dir_q: null\n","  freeze_d_model: 0\n","  agg: max\n","  fp16: true\n","\n","config:\n","  lr: 2.0e-05\n","  seed: 123\n","  gradient_accumulation_steps: 1\n","  weight_decay: 0.01\n","  validation_metrics:\n","  - MRR@10\n","  - recall@100\n","  - recall@200\n","  - recall@500\n","  pretrained_no_yamlconfig: false\n","  nb_iterations: 10\n","  train_batch_size: 6\n","  eval_batch_size: 8\n","  index_retrieve_batch_size: 6\n","  record_frequency: 3\n","  train_monitoring_freq: 2\n","  warmup_steps: 5\n","  max_length: 10\n","  fp16: false\n","  augment_pairs: in_batch_negatives\n","  matching_type: splade\n","  monitoring_ckpt: loss\n","  loss: InBatchPairwiseNLL\n","  regularizer:\n","    FLOPS:\n","      lambda_q: 0.0005\n","      lambda_d: 0.0003\n","      T: 3\n","      targeted_rep: rep\n","      reg: FLOPS\n","  tokenizer_type: distilbert-base-uncased\n","  top_k: 5\n","  threshold: 0.4\n","  eval_metric:\n","  - - mrr_10\n","    - recall\n","  checkpoint_dir: experiments/debug/checkpoint\n","  index_dir: experiments/debug/index\n","  out_dir: experiments/debug/out\n","data:\n","  type: triplets\n","  TRAIN_DATA_DIR: data/toy_data/triplets\n","  VALIDATION_SIZE_FOR_LOSS: 20\n","  VALIDATION_FULL_RANKING:\n","    D_COLLECTION_PATH: data/toy_data/val_collection\n","    Q_COLLECTION_PATH: data/toy_data/val_queries\n","    QREL_PATH: data/toy_data/qrel/qrel.json\n","    TOP_K: 20\n","  COLLECTION_PATH: data/toy_data/full_collection\n","  Q_COLLECTION_PATH:\n","  - data/toy_data/dev_queries\n","  EVAL_QREL_PATH:\n","  - data/toy_data/qrel/qrel.json\n","  flops_queries: data/toy_data/dev_queries\n","init_dict:\n","  model_type_or_dir: distilbert-base-uncased\n","  model_type_or_dir_q: null\n","  freeze_d_model: 0\n","  agg: max\n","  fp16: true\n","\n","Downloading: 100% 483/483 [00:00<00:00, 504kB/s]\n","Downloading: 100% 256M/256M [00:02<00:00, 130MB/s]\n","Downloading: 100% 28.0/28.0 [00:00<00:00, 27.3kB/s]\n","Downloading: 100% 226k/226k [00:00<00:00, 548kB/s]\n","Downloading: 100% 455k/455k [00:00<00:00, 731kB/s]\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","Preloading dataset\n","100it [00:00, 245712.01it/s]\n","initialize loader for validation loss\n","split train, originally 100 pairs\n","train: 80 pairs ~~ val: 20 pairs\n","Preloading dataset\n","20it [00:00, 163520.62it/s]\n","Preloading dataset\n","3it [00:00, 34192.70it/s]\n","WARNING: init evaluator, NOT restoring the model, NOT placing on device\n","+++++ BEGIN TRAINING +++++\n","initialize trainer...\n"," --- total number parameters: 66985530\n"," === trainer config === \n"," ========================= {'lr': 2e-05, 'seed': 123, 'gradient_accumulation_steps': 1, 'weight_decay': 0.01, 'validation_metrics': ['MRR@10', 'recall@100', 'recall@200', 'recall@500'], 'pretrained_no_yamlconfig': False, 'nb_iterations': 10, 'train_batch_size': 6, 'eval_batch_size': 8, 'index_retrieve_batch_size': 6, 'record_frequency': 3, 'train_monitoring_freq': 2, 'warmup_steps': 5, 'max_length': 10, 'fp16': False, 'augment_pairs': 'in_batch_negatives', 'matching_type': 'splade', 'monitoring_ckpt': 'loss', 'loss': 'InBatchPairwiseNLL', 'regularizer': {'FLOPS': {'lambda_q': 0.0005, 'lambda_d': 0.0003, 'T': 3, 'targeted_rep': 'rep', 'reg': 'FLOPS'}}, 'tokenizer_type': 'distilbert-base-uncased', 'top_k': 5, 'threshold': 0.4, 'eval_metric': [['mrr_10', 'recall']], 'checkpoint_dir': 'experiments/debug/checkpoint', 'index_dir': 'experiments/debug/index', 'out_dir': 'experiments/debug/out', 'val_full_rank_qrel_path': 'data/toy_data/qrel/qrel.json'}\n","Using FP16: False\n","  9% 1/11 [00:02<00:29,  2.91s/it]+batch_loss_iter2: 0.5289\n","~~VAL_RANKING_LOSS_iter3: 144.95735931396484\n","WARNING: init evaluator, NOT restoring the model, NOT placing on device\n","initializing new index...\n","\n","  0% 0/3 [00:00<?, ?it/s]\u001b[A\n","100% 3/3 [00:00<00:00,  7.43it/s]\n","WARNING: init evaluator, NOT restoring the model, NOT placing on device\n","\n","  0% 0/3 [00:00<?, ?it/s]\u001b[A\n","100% 3/3 [00:02<00:00,  1.17it/s]\n"," 27% 3/11 [00:10<00:28,  3.62s/it]+batch_loss_iter4: 180.4835\n"," 45% 5/11 [00:10<00:10,  1.80s/it]+batch_loss_iter6: 105.8335\n","~~VAL_RANKING_LOSS_iter6: 64.44827651977539\n","WARNING: init evaluator, NOT restoring the model, NOT placing on device\n","initializing new index...\n","\n","  0% 0/3 [00:00<?, ?it/s]\u001b[A\n","100% 3/3 [00:00<00:00,  7.28it/s]\n","WARNING: init evaluator, NOT restoring the model, NOT placing on device\n","\n","  0% 0/3 [00:00<?, ?it/s]\u001b[A\n","100% 3/3 [00:00<00:00,  6.53it/s]\n"," 55% 6/11 [00:16<00:14,  2.96s/it]+batch_loss_iter8: 5.4071\n"," 73% 8/11 [00:17<00:05,  1.71s/it]~~VAL_RANKING_LOSS_iter9: 44.166473388671875\n","WARNING: init evaluator, NOT restoring the model, NOT placing on device\n","initializing new index...\n","\n","  0% 0/3 [00:00<?, ?it/s]\u001b[A\n","100% 3/3 [00:00<00:00,  7.14it/s]\n","WARNING: init evaluator, NOT restoring the model, NOT placing on device\n","\n","  0% 0/3 [00:00<?, ?it/s]\u001b[A\n","100% 3/3 [00:00<00:00,  7.37it/s]\n"," 82% 9/11 [00:22<00:04,  2.47s/it]+batch_loss_iter10: 98.1634\n","100% 11/11 [00:22<00:00,  2.02s/it]\n","======= TRAINING DONE =======\n","took about 0.007785330878363715 hours\n","config:\n","  lr: 2.0e-05\n","  seed: 123\n","  gradient_accumulation_steps: 1\n","  weight_decay: 0.01\n","  validation_metrics:\n","  - MRR@10\n","  - recall@100\n","  - recall@200\n","  - recall@500\n","  pretrained_no_yamlconfig: false\n","  nb_iterations: 10\n","  train_batch_size: 6\n","  eval_batch_size: 8\n","  index_retrieve_batch_size: 6\n","  record_frequency: 3\n","  train_monitoring_freq: 2\n","  warmup_steps: 5\n","  max_length: 10\n","  fp16: false\n","  augment_pairs: in_batch_negatives\n","  matching_type: splade\n","  monitoring_ckpt: loss\n","  loss: InBatchPairwiseNLL\n","  regularizer:\n","    FLOPS:\n","      lambda_q: 0.0005\n","      lambda_d: 0.0003\n","      T: 3\n","      targeted_rep: rep\n","      reg: FLOPS\n","  tokenizer_type: distilbert-base-uncased\n","  top_k: 5\n","  threshold: 0.4\n","  eval_metric:\n","  - - mrr_10\n","    - recall\n","  checkpoint_dir: experiments/debug/checkpoint\n","  index_dir: experiments/debug/index\n","  out_dir: experiments/debug/out\n","  val_full_rank_qrel_path: data/toy_data/qrel/qrel.json\n","  ckpt_step: 11\n","data:\n","  type: triplets\n","  TRAIN_DATA_DIR: data/toy_data/triplets\n","  VALIDATION_SIZE_FOR_LOSS: 20\n","  VALIDATION_FULL_RANKING:\n","    D_COLLECTION_PATH: data/toy_data/val_collection\n","    Q_COLLECTION_PATH: data/toy_data/val_queries\n","    QREL_PATH: data/toy_data/qrel/qrel.json\n","    TOP_K: 20\n","  COLLECTION_PATH: data/toy_data/full_collection\n","  Q_COLLECTION_PATH:\n","  - data/toy_data/dev_queries\n","  EVAL_QREL_PATH:\n","  - data/toy_data/qrel/qrel.json\n","  flops_queries: data/toy_data/dev_queries\n","init_dict:\n","  model_type_or_dir: distilbert-base-uncased\n","  model_type_or_dir_q: null\n","  freeze_d_model: 0\n","  agg: max\n","  fp16: false\n","\n","Preloading dataset\n","89it [00:00, 251545.19it/s]\n","restoring model: Splade\n","restore model on GPU at experiments/debug/checkpoint/model/model.tar\n","initializing new index...\n","100% 15/15 [00:01<00:00, 13.07it/s]\n","converting to numpy\n","100% 20828/20828 [00:00<00:00, 345772.05it/s]\n","save to disk\n","100% 20828/20828 [00:05<00:00, 3481.73it/s]\n","saving index distribution...\n","done iterating over the corpus...\n","index contains 20828 posting lists\n","index contains 89 documents\n","config:\n","  lr: 2.0e-05\n","  seed: 123\n","  gradient_accumulation_steps: 1\n","  weight_decay: 0.01\n","  validation_metrics:\n","  - MRR@10\n","  - recall@100\n","  - recall@200\n","  - recall@500\n","  pretrained_no_yamlconfig: false\n","  nb_iterations: 10\n","  train_batch_size: 6\n","  eval_batch_size: 8\n","  index_retrieve_batch_size: 6\n","  record_frequency: 3\n","  train_monitoring_freq: 2\n","  warmup_steps: 5\n","  max_length: 10\n","  fp16: false\n","  augment_pairs: in_batch_negatives\n","  matching_type: splade\n","  monitoring_ckpt: loss\n","  loss: InBatchPairwiseNLL\n","  regularizer:\n","    FLOPS:\n","      lambda_q: 0.0005\n","      lambda_d: 0.0003\n","      T: 3\n","      targeted_rep: rep\n","      reg: FLOPS\n","  tokenizer_type: distilbert-base-uncased\n","  top_k: 5\n","  threshold: 0.4\n","  eval_metric:\n","  - - mrr_10\n","    - recall\n","  checkpoint_dir: experiments/debug/checkpoint\n","  index_dir: experiments/debug/index\n","  out_dir: experiments/debug/out\n","  val_full_rank_qrel_path: data/toy_data/qrel/qrel.json\n","  ckpt_step: 11\n","data:\n","  type: triplets\n","  TRAIN_DATA_DIR: data/toy_data/triplets\n","  VALIDATION_SIZE_FOR_LOSS: 20\n","  VALIDATION_FULL_RANKING:\n","    D_COLLECTION_PATH: data/toy_data/val_collection\n","    Q_COLLECTION_PATH: data/toy_data/val_queries\n","    QREL_PATH: data/toy_data/qrel/qrel.json\n","    TOP_K: 20\n","  COLLECTION_PATH: data/toy_data/full_collection\n","  Q_COLLECTION_PATH:\n","  - data/toy_data/dev_queries\n","  EVAL_QREL_PATH:\n","  - data/toy_data/qrel/qrel.json\n","  flops_queries: data/toy_data/dev_queries\n","init_dict:\n","  model_type_or_dir: distilbert-base-uncased\n","  model_type_or_dir_q: null\n","  freeze_d_model: 0\n","  agg: max\n","  fp16: false\n","\n","Preloading dataset\n","3it [00:00, 33200.30it/s]\n","restoring model: Splade\n","restore model on GPU at experiments/debug/checkpoint/model/model.tar\n","index already exists, loading...\n","100% 30522/30522 [00:10<00:00, 2949.87it/s]\n","done loading index...\n","100% 3/3 [00:01<00:00,  1.59it/s]\n","['mrr_10', 'recall']\n","MRR@10: 0.0\n","recall ==> {}\n","config:\n","  lr: 2.0e-05\n","  seed: 123\n","  gradient_accumulation_steps: 1\n","  weight_decay: 0.01\n","  validation_metrics:\n","  - MRR@10\n","  - recall@100\n","  - recall@200\n","  - recall@500\n","  pretrained_no_yamlconfig: false\n","  nb_iterations: 10\n","  train_batch_size: 6\n","  eval_batch_size: 8\n","  index_retrieve_batch_size: 6\n","  record_frequency: 3\n","  train_monitoring_freq: 2\n","  warmup_steps: 5\n","  max_length: 10\n","  fp16: false\n","  augment_pairs: in_batch_negatives\n","  matching_type: splade\n","  monitoring_ckpt: loss\n","  loss: InBatchPairwiseNLL\n","  regularizer:\n","    FLOPS:\n","      lambda_q: 0.0005\n","      lambda_d: 0.0003\n","      T: 3\n","      targeted_rep: rep\n","      reg: FLOPS\n","  tokenizer_type: distilbert-base-uncased\n","  top_k: 5\n","  threshold: 0.4\n","  eval_metric:\n","  - - mrr_10\n","    - recall\n","  checkpoint_dir: experiments/debug/checkpoint\n","  index_dir: experiments/debug/index\n","  out_dir: experiments/debug/out\n","  val_full_rank_qrel_path: data/toy_data/qrel/qrel.json\n","  ckpt_step: 11\n","data:\n","  type: triplets\n","  TRAIN_DATA_DIR: data/toy_data/triplets\n","  VALIDATION_SIZE_FOR_LOSS: 20\n","  VALIDATION_FULL_RANKING:\n","    D_COLLECTION_PATH: data/toy_data/val_collection\n","    Q_COLLECTION_PATH: data/toy_data/val_queries\n","    QREL_PATH: data/toy_data/qrel/qrel.json\n","    TOP_K: 20\n","  COLLECTION_PATH: data/toy_data/full_collection\n","  Q_COLLECTION_PATH:\n","  - data/toy_data/dev_queries\n","  EVAL_QREL_PATH:\n","  - data/toy_data/qrel/qrel.json\n","  flops_queries: data/toy_data/dev_queries\n","init_dict:\n","  model_type_or_dir: distilbert-base-uncased\n","  model_type_or_dir_q: null\n","  freeze_d_model: 0\n","  agg: max\n","  fp16: false\n","\n","Preloading dataset\n","3it [00:00, 43092.16it/s]\n","LOAD MODEL AND DOCUMENT INDEX\n","restoring model: Splade\n","restore model on GPU at experiments/debug/checkpoint/model/model.tar\n","index already exists, loading...\n","100% 20828/20828 [00:07<00:00, 2617.68it/s]\n","done loading index...\n","CREATE QUERY INDEX\n","WARNING: init evaluator, NOT restoring the model, NOT placing on device\n","initializing new index...\n","100% 1/1 [00:00<00:00,  5.36it/s]\n","{'flops': 932.9213483146068}\n","config:\n","  lr: 2.0e-05\n","  seed: 123\n","  gradient_accumulation_steps: 1\n","  weight_decay: 0.01\n","  validation_metrics:\n","  - MRR@10\n","  - recall@100\n","  - recall@200\n","  - recall@500\n","  pretrained_no_yamlconfig: false\n","  nb_iterations: 10\n","  train_batch_size: 6\n","  eval_batch_size: 8\n","  index_retrieve_batch_size: 6\n","  record_frequency: 3\n","  train_monitoring_freq: 2\n","  warmup_steps: 5\n","  max_length: 10\n","  fp16: false\n","  augment_pairs: in_batch_negatives\n","  matching_type: splade\n","  monitoring_ckpt: loss\n","  loss: InBatchPairwiseNLL\n","  regularizer:\n","    FLOPS:\n","      lambda_q: 0.0005\n","      lambda_d: 0.0003\n","      T: 3\n","      targeted_rep: rep\n","      reg: FLOPS\n","  tokenizer_type: distilbert-base-uncased\n","  top_k: 5\n","  threshold: 0.4\n","  eval_metric:\n","  - - mrr_10\n","    - recall\n","  checkpoint_dir: experiments/debug/checkpoint\n","  index_dir: experiments/debug/index\n","  out_dir: experiments/debug/out\n","  val_full_rank_qrel_path: data/toy_data/qrel/qrel.json\n","  ckpt_step: 11\n","data:\n","  type: triplets\n","  TRAIN_DATA_DIR: data/toy_data/triplets\n","  VALIDATION_SIZE_FOR_LOSS: 20\n","  VALIDATION_FULL_RANKING:\n","    D_COLLECTION_PATH: data/toy_data/val_collection\n","    Q_COLLECTION_PATH: data/toy_data/val_queries\n","    QREL_PATH: data/toy_data/qrel/qrel.json\n","    TOP_K: 20\n","  COLLECTION_PATH: data/toy_data/full_collection\n","  Q_COLLECTION_PATH:\n","  - data/toy_data/dev_queries\n","  EVAL_QREL_PATH:\n","  - data/toy_data/qrel/qrel.json\n","  flops_queries: data/toy_data/dev_queries\n","init_dict:\n","  model_type_or_dir: distilbert-base-uncased\n","  model_type_or_dir_q: null\n","  freeze_d_model: 0\n","  agg: max\n","  fp16: false\n","\n","experiments/debug/index/index_dist.png\n"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["base_model_prefix"],"metadata":{"id":"2fIZiLwpFxNc"},"execution_count":null,"outputs":[]}]}